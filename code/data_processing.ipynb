{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection:\n",
    "\n",
    "The dataset is available in UC Irvine Machine Learning Repository. We followed the import in Python instructions on the website to get the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\saani\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\saani\\anaconda3\\lib\\site-packages (from ucimlrepo) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\saani\\anaconda3\\lib\\site-packages (from ucimlrepo) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saani\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saani\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\saani\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\saani\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saani\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 222, 'name': 'Bank Marketing', 'repository_url': 'https://archive.ics.uci.edu/dataset/222/bank+marketing', 'data_url': 'https://archive.ics.uci.edu/static/public/222/data.csv', 'abstract': 'The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).', 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 45211, 'num_features': 16, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Occupation', 'Marital Status', 'Education Level'], 'target_col': ['y'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2014, 'last_updated': 'Fri Aug 18 2023', 'dataset_doi': '10.24432/C5K306', 'creators': ['S. Moro', 'P. Rita', 'P. Cortez'], 'intro_paper': {'ID': 277, 'type': 'NATIVE', 'title': 'A data-driven approach to predict the success of bank telemarketing', 'authors': 'SÃ©rgio Moro, P. Cortez, P. Rita', 'venue': 'Decision Support Systems', 'year': 2014, 'journal': None, 'DOI': '10.1016/j.dss.2014.03.001', 'URL': 'https://www.semanticscholar.org/paper/cab86052882d126d43f72108c6cb41b295cc8a9e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \\n\\nThere are four datasets: \\n1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]\\n2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.\\n3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). \\n4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). \\nThe smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). \\n\\nThe classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Input variables:\\n   # bank client data:\\n   1 - age (numeric)\\n   2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\\n                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \\n   3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\\n   4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\\n   5 - default: has credit in default? (binary: \"yes\",\"no\")\\n   6 - balance: average yearly balance, in euros (numeric) \\n   7 - housing: has housing loan? (binary: \"yes\",\"no\")\\n   8 - loan: has personal loan? (binary: \"yes\",\"no\")\\n   # related with the last contact of the current campaign:\\n   9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \\n  10 - day: last contact day of the month (numeric)\\n  11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\\n  12 - duration: last contact duration, in seconds (numeric)\\n   # other attributes:\\n  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\\n  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\\n  15 - previous: number of contacts performed before this campaign and for this client (numeric)\\n  16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\\n\\n  Output variable (desired target):\\n  17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\\n', 'citation': None}}\n",
      "           name     role         type      demographic  \\\n",
      "0           age  Feature      Integer              Age   \n",
      "1           job  Feature  Categorical       Occupation   \n",
      "2       marital  Feature  Categorical   Marital Status   \n",
      "3     education  Feature  Categorical  Education Level   \n",
      "4       default  Feature       Binary             None   \n",
      "5       balance  Feature      Integer             None   \n",
      "6       housing  Feature       Binary             None   \n",
      "7          loan  Feature       Binary             None   \n",
      "8       contact  Feature  Categorical             None   \n",
      "9   day_of_week  Feature         Date             None   \n",
      "10        month  Feature         Date             None   \n",
      "11     duration  Feature      Integer             None   \n",
      "12     campaign  Feature      Integer             None   \n",
      "13        pdays  Feature      Integer             None   \n",
      "14     previous  Feature      Integer             None   \n",
      "15     poutcome  Feature  Categorical             None   \n",
      "16            y   Target       Binary             None   \n",
      "\n",
      "                                          description  units missing_values  \n",
      "0                                                None   None             no  \n",
      "1   type of job (categorical: 'admin.','blue-colla...   None             no  \n",
      "2   marital status (categorical: 'divorced','marri...   None             no  \n",
      "3   (categorical: 'basic.4y','basic.6y','basic.9y'...   None             no  \n",
      "4                              has credit in default?   None             no  \n",
      "5                              average yearly balance  euros             no  \n",
      "6                                   has housing loan?   None             no  \n",
      "7                                  has personal loan?   None             no  \n",
      "8   contact communication type (categorical: 'cell...   None            yes  \n",
      "9                        last contact day of the week   None             no  \n",
      "10  last contact month of year (categorical: 'jan'...   None             no  \n",
      "11   last contact duration, in seconds (numeric). ...   None             no  \n",
      "12  number of contacts performed during this campa...   None             no  \n",
      "13  number of days that passed by after the client...   None            yes  \n",
      "14  number of contacts performed before this campa...   None             no  \n",
      "15  outcome of the previous marketing campaign (ca...   None            yes  \n",
      "16          has the client subscribed a term deposit?   None             no  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = bank_marketing.data.features \n",
    "y = bank_marketing.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(bank_marketing.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(bank_marketing.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age           job  marital  education default  balance housing loan  \\\n",
      "0   58    management  married   tertiary      no     2143     yes   no   \n",
      "1   44    technician   single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar  married        NaN      no     1506     yes   no   \n",
      "4   33           NaN   single        NaN      no        1      no   no   \n",
      "\n",
      "  contact  day_of_week month  duration  campaign  pdays  previous poutcome   y  \n",
      "0     NaN            5   may       261         1     -1         0      NaN  no  \n",
      "1     NaN            5   may       151         1     -1         0      NaN  no  \n",
      "2     NaN            5   may        76         1     -1         0      NaN  no  \n",
      "3     NaN            5   may        92         1     -1         0      NaN  no  \n",
      "4     NaN            5   may       198         1     -1         0      NaN  no  \n",
      "y\n",
      "no     39922\n",
      "yes     5289\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop the 'y' column from X to avoid duplication\n",
    "if 'y' in X.columns:\n",
    "    X = X.drop(columns='y')\n",
    "\n",
    "# 2. Concatenate X and y safely\n",
    "X = pd.concat([X, y], axis=1)\n",
    "\n",
    "# 3. Drop rows where y is NaN\n",
    "X = X.dropna(subset=['y'])\n",
    "\n",
    "# 4. (Optional) Check your data\n",
    "print(X.head())\n",
    "print(X['y'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          45211 non-null  int64 \n",
      " 1   job          44923 non-null  object\n",
      " 2   marital      45211 non-null  object\n",
      " 3   education    43354 non-null  object\n",
      " 4   default      45211 non-null  object\n",
      " 5   balance      45211 non-null  int64 \n",
      " 6   housing      45211 non-null  object\n",
      " 7   loan         45211 non-null  object\n",
      " 8   contact      32191 non-null  object\n",
      " 9   day_of_week  45211 non-null  int64 \n",
      " 10  month        45211 non-null  object\n",
      " 11  duration     45211 non-null  int64 \n",
      " 12  campaign     45211 non-null  int64 \n",
      " 13  pdays        45211 non-null  int64 \n",
      " 14  previous     45211 non-null  int64 \n",
      " 15  poutcome     8252 non-null   object\n",
      " 16  y            45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#To know the data types and missing data points \n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>258.163080</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>257.527812</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance   day_of_week      duration      campaign  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
       "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
       "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
       "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
       "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
       "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
       "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
       "\n",
       "              pdays      previous  \n",
       "count  45211.000000  45211.000000  \n",
       "mean      40.197828      0.580323  \n",
       "std      100.128746      2.303441  \n",
       "min       -1.000000      0.000000  \n",
       "25%       -1.000000      0.000000  \n",
       "50%       -1.000000      0.000000  \n",
       "75%       -1.000000      0.000000  \n",
       "max      871.000000    275.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#descriptive statistics\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 17)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#droping duplicates if they exist\n",
    "X.drop_duplicates(keep='first',inplace=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job</td>\n",
       "      <td>0.637013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>education</td>\n",
       "      <td>4.107407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contact</td>\n",
       "      <td>28.798301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>81.747805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  null_count\n",
       "0        job    0.637013\n",
       "1  education    4.107407\n",
       "2    contact   28.798301\n",
       "3   poutcome   81.747805"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handling Null Values: Part 1\n",
    "X_null=X.isna().sum().to_frame('null_count').reset_index()\n",
    "X_null=X_null[X_null['null_count']>0].reset_index(drop=True)\n",
    "\n",
    "X_null['null_count']=X_null['null_count']*100/X.shape[0]\n",
    "X_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          45211 non-null  int64 \n",
      " 1   job          44923 non-null  object\n",
      " 2   marital      45211 non-null  object\n",
      " 3   education    43354 non-null  object\n",
      " 4   default      45211 non-null  object\n",
      " 5   balance      45211 non-null  int64 \n",
      " 6   housing      45211 non-null  object\n",
      " 7   loan         45211 non-null  object\n",
      " 8   contact      32191 non-null  object\n",
      " 9   day_of_week  45211 non-null  int64 \n",
      " 10  month        45211 non-null  object\n",
      " 11  duration     45211 non-null  int64 \n",
      " 12  campaign     45211 non-null  int64 \n",
      " 13  pdays        45211 non-null  int64 \n",
      " 14  previous     45211 non-null  int64 \n",
      " 15  y            45211 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Handling Null Values: Part 2, dropping columns with more than 80% null_values. The threshold can be set based on the dataset.\n",
    "columns_to_drop = X_null[X_null['null_count'] > 80]['index'].tolist()\n",
    "X.drop(columns=columns_to_drop,inplace=True)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values imputed successfully!\n",
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day_of_week', 'month', 'duration', 'campaign',\n",
      "       'pdays', 'previous', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Handling Null Values: Part 3, we are goimng to impute columns with <80% missing values\n",
    "\n",
    "# Step 1: Identify columns with <80% missing values\n",
    "impute = X_null[X_null['null_count'] < 80]['index'].tolist()\n",
    "\n",
    "# Step 2: Iterate through each column and impute missing values\n",
    "for i in impute:\n",
    "    # Check if the column is categorical (dtype is 'object')\n",
    "    if X[i].dtype == 'object':\n",
    "        # Fill missing values with the most frequent value (mode)\n",
    "        X[i].fillna(X[i].mode()[0], inplace=True)\n",
    "    else:\n",
    "        # Fill missing values in numerical columns with median (immune to outliers)\n",
    "        X[i].fillna(X[i].median(), inplace=True)\n",
    "\n",
    "print(\"Missing values imputed successfully!\")\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         no\n",
       "1         no\n",
       "2         no\n",
       "3         no\n",
       "4         no\n",
       "        ... \n",
       "45206    yes\n",
       "45207    yes\n",
       "45208    yes\n",
       "45209     no\n",
       "45210     no\n",
       "Name: y, Length: 45211, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the null values are handled\n",
    "X.isna().sum()\n",
    "X['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning numerical and categorical values\n",
    "X_numerical=X[X.describe().columns]\n",
    "X_categorical=X[[i for i in X.columns if i not in X_numerical.columns ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  month  month_encoded\n",
      "0   may              5\n",
      "1   may              5\n",
      "2   may              5\n",
      "3   may              5\n",
      "4   may              5\n",
      "<bound method NDFrame.head of        age           job   marital  education default  balance housing loan  \\\n",
      "0       58    management   married   tertiary      no     2143     yes   no   \n",
      "1       44    technician    single  secondary      no       29     yes   no   \n",
      "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
      "3       47   blue-collar   married  secondary      no     1506     yes   no   \n",
      "4       33   blue-collar    single  secondary      no        1      no   no   \n",
      "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
      "45206   51    technician   married   tertiary      no      825      no   no   \n",
      "45207   71       retired  divorced    primary      no     1729      no   no   \n",
      "45208   72       retired   married  secondary      no     5715      no   no   \n",
      "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
      "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
      "\n",
      "         contact  day_of_week month  duration  campaign  pdays  previous    y  \\\n",
      "0       cellular            5   may       261         1     -1         0   no   \n",
      "1       cellular            5   may       151         1     -1         0   no   \n",
      "2       cellular            5   may        76         1     -1         0   no   \n",
      "3       cellular            5   may        92         1     -1         0   no   \n",
      "4       cellular            5   may       198         1     -1         0   no   \n",
      "...          ...          ...   ...       ...       ...    ...       ...  ...   \n",
      "45206   cellular           17   nov       977         3     -1         0  yes   \n",
      "45207   cellular           17   nov       456         2     -1         0  yes   \n",
      "45208   cellular           17   nov      1127         5    184         3  yes   \n",
      "45209  telephone           17   nov       508         4     -1         0   no   \n",
      "45210   cellular           17   nov       361         2    188        11   no   \n",
      "\n",
      "       month_encoded  \n",
      "0                  5  \n",
      "1                  5  \n",
      "2                  5  \n",
      "3                  5  \n",
      "4                  5  \n",
      "...              ...  \n",
      "45206             11  \n",
      "45207             11  \n",
      "45208             11  \n",
      "45209             11  \n",
      "45210             11  \n",
      "\n",
      "[45211 rows x 17 columns]>\n"
     ]
    }
   ],
   "source": [
    "# We are encoding categorical values \n",
    "\n",
    "# 1) Month- we are doing ordinal encoding \n",
    "\n",
    "# Define the ordinal mapping\n",
    "month_order = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, \n",
    "               'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "\n",
    "# Apply ordinal encoding\n",
    "X['month_encoded'] = X['month'].map(month_order)\n",
    "\n",
    "print(X[['month', 'month_encoded']].head())\n",
    "print(X.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            job  job_encoded\n",
      "0    management            4\n",
      "1    technician            9\n",
      "2  entrepreneur            2\n",
      "3   blue-collar            1\n",
      "4   blue-collar            1\n",
      "   marital  marital_encoded\n",
      "0  married                1\n",
      "1   single                2\n",
      "2  married                1\n",
      "3  married                1\n",
      "4   single                2\n",
      "    contact  contact_encoded\n",
      "0  cellular                0\n",
      "1  cellular                0\n",
      "2  cellular                0\n",
      "3  cellular                0\n",
      "4  cellular                0\n"
     ]
    }
   ],
   "source": [
    "# 2- job, maritial, contactwe are currently going with label encoding since it's good for tree based models may change in the future\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder for 'job'\n",
    "le_job = LabelEncoder()\n",
    "X['job_encoded'] = le_job.fit_transform(X['job'])\n",
    "\n",
    "print(X[['job', 'job_encoded']].head())\n",
    "\n",
    "# Initialize LabelEncoder for 'marital'\n",
    "le_marital = LabelEncoder()\n",
    "X['marital_encoded'] = le_marital.fit_transform(X['marital'])\n",
    "\n",
    "print(X[['marital', 'marital_encoded']].head())\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le_contact = LabelEncoder()\n",
    "\n",
    "# Apply encoding\n",
    "X['contact_encoded'] = le_contact.fit_transform(X['contact'])\n",
    "\n",
    "# Display results\n",
    "print(X[['contact', 'contact_encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   education  education_encoded\n",
      "0   tertiary                2.0\n",
      "1  secondary                1.0\n",
      "2  secondary                1.0\n",
      "3  secondary                1.0\n",
      "4  secondary                1.0\n"
     ]
    }
   ],
   "source": [
    "#3- education ordinal encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Define the order of education levels\n",
    "education_order = [['primary', 'secondary', 'tertiary']]\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=education_order)\n",
    "\n",
    "# Apply encoding\n",
    "X['education_encoded'] = ordinal_encoder.fit_transform(X[['education']])\n",
    "\n",
    "print(X[['education', 'education_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan\n",
       "no     37967\n",
       "yes     7244\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['loan'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  default  default_encoded housing  housing_encoded loan  loan_encoded   y  \\\n",
      "0      no                0     yes                1   no             0  no   \n",
      "1      no                0     yes                1   no             0  no   \n",
      "2      no                0     yes                1  yes             1  no   \n",
      "3      no                0     yes                1   no             0  no   \n",
      "4      no                0      no                0   no             0  no   \n",
      "\n",
      "   y_encoded  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "#4- Binary columns yes/ no- binary encoding\n",
    "\n",
    "# Define mapping for Yes/No columns\n",
    "binary_mapping = {'yes': 1, 'no': 0}\n",
    "\n",
    "# Apply encoding\n",
    "X['default_encoded'] = X['default'].map(binary_mapping)\n",
    "X['housing_encoded'] = X['housing'].map(binary_mapping)\n",
    "X['loan_encoded'] = X['loan'].map(binary_mapping)\n",
    "X['y_encoded']=X['y'].map(binary_mapping)\n",
    "# Display results\n",
    "print(X[['default', 'default_encoded', 'housing', 'housing_encoded', 'loan', 'loan_encoded','y','y_encoded']].head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping redundant categorical columns:\n",
      "   age  balance  day_of_week  duration  campaign  pdays  previous  \\\n",
      "0   58     2143            5       261         1     -1         0   \n",
      "1   44       29            5       151         1     -1         0   \n",
      "2   33        2            5        76         1     -1         0   \n",
      "3   47     1506            5        92         1     -1         0   \n",
      "4   33        1            5       198         1     -1         0   \n",
      "\n",
      "   month_encoded  job_encoded  marital_encoded  contact_encoded  \\\n",
      "0              5            4                1                0   \n",
      "1              5            9                2                0   \n",
      "2              5            2                1                0   \n",
      "3              5            1                1                0   \n",
      "4              5            1                2                0   \n",
      "\n",
      "   education_encoded  default_encoded  housing_encoded  loan_encoded  \\\n",
      "0                2.0                0                1             0   \n",
      "1                1.0                0                1             0   \n",
      "2                1.0                0                1             1   \n",
      "3                1.0                0                1             0   \n",
      "4                1.0                0                0             0   \n",
      "\n",
      "   y_encoded  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "Index(['age', 'balance', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'month_encoded', 'job_encoded', 'marital_encoded',\n",
      "       'contact_encoded', 'education_encoded', 'default_encoded',\n",
      "       'housing_encoded', 'loan_encoded', 'y_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop original categorical columns as they have encoded versions\n",
    "categorical_columns = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"y\"]\n",
    "X = X.drop(columns=categorical_columns, errors=\"ignore\")\n",
    "\n",
    "# Display the dataframe after dropping redundant columns\n",
    "print(\"Columns after dropping redundant categorical columns:\")\n",
    "print(X.head())\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset after normalization and standardization:\n",
      "                age       balance   day_of_week      duration      campaign  \\\n",
      "count  4.521100e+04  4.521100e+04  4.521100e+04  4.521100e+04  4.521100e+04   \n",
      "mean   2.112250e-16 -2.942063e-15  1.257292e-17  7.065980e-16 -3.520417e-17   \n",
      "std    1.000011e+00  1.000011e+00  1.000011e+00  1.000011e+00  1.000011e+00   \n",
      "min   -2.159994e+00 -3.968321e+01 -1.779108e+00 -4.928214e+00 -9.094571e-01   \n",
      "25%   -7.473845e-01 -5.652955e-01 -9.380027e-01 -5.788669e-01 -9.094571e-01   \n",
      "50%   -1.823406e-01 -3.514087e-01  2.326031e-02  2.513596e-02 -1.171495e-01   \n",
      "75%    6.652252e-01  1.643000e-01  6.240497e-01  6.482326e-01  4.450018e-01   \n",
      "max    5.091402e+00  1.173122e+01  1.825628e+00  3.645616e+00  5.862837e+00   \n",
      "\n",
      "              pdays      previous  month_encoded   job_encoded  \\\n",
      "count  4.521100e+04  4.521100e+04   45211.000000  45211.000000   \n",
      "mean   4.023334e-17 -1.408167e-16       6.144655      4.276061   \n",
      "std    1.000011e+00  1.000011e+00       2.408034      3.239553   \n",
      "min   -4.662957e-01 -4.058977e-01       1.000000      0.000000   \n",
      "25%   -4.662957e-01 -4.058977e-01       5.000000      1.000000   \n",
      "50%   -4.662957e-01 -4.058977e-01       6.000000      4.000000   \n",
      "75%   -4.662957e-01 -4.058977e-01       8.000000      7.000000   \n",
      "max    2.935375e+00  1.289319e+01      12.000000     10.000000   \n",
      "\n",
      "       marital_encoded  contact_encoded  education_encoded  default_encoded  \\\n",
      "count     45211.000000     45211.000000       45211.000000     45211.000000   \n",
      "mean          1.167725         0.064276           1.142664         0.018027   \n",
      "std           0.608230         0.245247           0.652218         0.133049   \n",
      "min           0.000000         0.000000           0.000000         0.000000   \n",
      "25%           1.000000         0.000000           1.000000         0.000000   \n",
      "50%           1.000000         0.000000           1.000000         0.000000   \n",
      "75%           2.000000         0.000000           2.000000         0.000000   \n",
      "max           2.000000         1.000000           2.000000         1.000000   \n",
      "\n",
      "       housing_encoded  loan_encoded     y_encoded  \n",
      "count     45211.000000  45211.000000  45211.000000  \n",
      "mean          0.555838      0.160226      0.116985  \n",
      "std           0.496878      0.366820      0.321406  \n",
      "min           0.000000      0.000000      0.000000  \n",
      "25%           0.000000      0.000000      0.000000  \n",
      "50%           1.000000      0.000000      0.000000  \n",
      "75%           1.000000      0.000000      0.000000  \n",
      "max           1.000000      1.000000      1.000000  \n",
      "Final dataset shape: (45211, 16)\n",
      "Final dataset info:\n",
      "Index(['age', 'balance', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
      "       'previous', 'month_encoded', 'job_encoded', 'marital_encoded',\n",
      "       'contact_encoded', 'education_encoded', 'default_encoded',\n",
      "       'housing_encoded', 'loan_encoded', 'y_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical columns (excluding encoded categorical features)\n",
    "numerical_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if not col.endswith(\"_encoded\")]\n",
    "\n",
    "# Identify binary numerical columns (0/1 values but NOT `_encoded`)\n",
    "binary_cols = [col for col in numerical_cols if set(X[col].dropna().unique()).issubset({0, 1})]\n",
    "\n",
    "# Separate non-binary numerical columns\n",
    "non_binary_numerical_cols = [col for col in numerical_cols if col not in binary_cols]\n",
    "\n",
    "# Check for skewness in non-binary numerical columns\n",
    "skewed_cols = X[non_binary_numerical_cols].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "# Apply log transformation to highly skewed non-binary numerical columns (absolute skewness > 1)\n",
    "for col in skewed_cols[abs(skewed_cols) > 1].index:\n",
    "    if (X[col] <= 0).any():  # If there are zero or negative values, shift before log transformation\n",
    "        X[col] = np.log1p(X[col] - X[col].min() + 1)\n",
    "    else:\n",
    "        X[col] = np.log1p(X[col])\n",
    "\n",
    "# Standardize only non-binary numerical features\n",
    "scaler = StandardScaler()\n",
    "X[non_binary_numerical_cols] = scaler.fit_transform(X[non_binary_numerical_cols])\n",
    "\n",
    "# Ensure binary columns are untouched (0/1)\n",
    "for col in binary_cols:\n",
    "    X[col] = X[col].astype(int)  # Convert back to ensure no changes\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Final dataset after normalization and standardization:\")\n",
    "print(X.describe())\n",
    "\n",
    "# Final check\n",
    "print(\"Final dataset shape:\", X.shape)\n",
    "print(\"Final dataset info:\")\n",
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully at: d:\\NEU\\Spring 2025\\Data_Mining\\Predictive-Modeling-for-Bank-Term-Deposit-Subscriptions\\data\\Data Preprocessing\\data_processing.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Move one level up from the current directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "\n",
    "# Define the destination path dynamically\n",
    "save_path = os.path.join(parent_dir, \"data\", \"Data Preprocessing\", \"data_processing.csv\")\n",
    "\n",
    "X=X.rename(columns={'y_encoded':'y'})\n",
    "\n",
    "# Save X as a CSV file\n",
    "X.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Dataset saved successfully at: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final Dataset Summary**\n",
    "\n",
    "- The dataset is now **clean, structured, and fully prepared for model training**.  \n",
    "- **All missing values are handled**, and categorical variables are properly encoded.  \n",
    "- **Redundant duplicate columns have been removed**, ensuring only necessary features are retained.  \n",
    "- **Numerical features have been standardized/normalized**, improving model performance and ensuring consistency in scale.  \n",
    "- The dataset is now **optimized and ready to be used for predictive modeling**. ð  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default_encoded\n",
       "0    44396\n",
       "1      815\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['default_encoded'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
